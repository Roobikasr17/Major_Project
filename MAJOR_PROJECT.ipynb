{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Alright, let's dive into this semiconductor manufacturing yield prediction challenge. It sounds like a fascinating problem where identifying the key process signals can lead to significant improvements. I'll follow your outlined steps to analyze the data, build predictive models, and determine the most important features.\n",
        "\n",
        "1. Import and Explore the Data\n",
        "\n",
        "\n",
        "First things first, let's import the plore the Data necessary libraries and load the dataset.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VhauhJHSwM3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vtSpV8OxZSxm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eEq8XlEaZTQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check current working directory\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "\n",
        "# List files in the current directory\n",
        "print(\"Files in the current directory:\", os.listdir())\n",
        "\n",
        "# Try loading the file with the correct path\n",
        "df = pd.read_csv('sensor-data.csv')  # Update the path as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgjMV7TCr9v7",
        "outputId": "1a1f6268-f0b3-48c3-e1b5-36cbf3556c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n",
            "Files in the current directory: ['.config', 'sensor-data.csv', 'sensor-data (2).csv', 'sensor-data (1).csv', 'sensor-data (3).csv', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This initial exploration gives us a glimpse into the data:\n",
        " * We have 1567 rows (production entities) and 592 columns (591 features + 1 target variable).\n",
        " * The features seem to be numerical.\n",
        " * The target variable '-1' represents the yield (1 for Fail, -1 for Pass).\n",
        " * The describe() output provides basic statistics like mean, standard deviation, and percentiles for each feature. This can give us an initial idea of the data's spread and potential outliers.\n",
        " * The target variable distribution shows an imbalance, with more 'Pass' (-1) instances than 'Fail' (1). This will need to be addressed during preprocessing."
      ],
      "metadata": {
        "id": "Mys4SxZmw-cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data Cleansing\n",
        "Now, let's handle missing values and consider dropping any irrelevant attributes based on the problem description."
      ],
      "metadata": {
        "id": "c1FTt8DlxPWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For the remaining missing values, we can impute them. Let's use the mean for now.\n",
        "# Note: More sophisticated imputation techniques could be explored."
      ],
      "metadata": {
        "id": "DSZ1Kkr8xiWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace this with your actual file name\n",
        "filename = 'your_file.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(filename)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(\"Missing values per column:\")\n",
        "    print(df.isnull().sum().sort_values(ascending=False).head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{filename}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc-1ku0jh6eC",
        "outputId": "4f0d886b-c623-40a1-8d52-0c4cc084ff1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file 'your_file.csv' was not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the numeric columns for imputation\n",
        "numeric_cols = df_cleaned.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Fill missing values for numeric columns\n",
        "df_imputed = df_cleaned.copy()\n",
        "df_imputed[numeric_cols] = df_imputed[numeric_cols].fillna(df_imputed[numeric_cols].mean())\n",
        "\n",
        "# Check for missing values after imputation\n",
        "print(\"\\nNumber of missing values after imputation:\")\n",
        "print(df_imputed.isnull().sum().max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoWFJV_ipsd2",
        "outputId": "4c3722b8-b331-46ed-e910-13da9316dcbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of missing values after imputation:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The problem description mentions a timestamp, but the initial data exploration didn't explicitly show a separate timestamp column.\n",
        "# If any of the 591 features implicitly represent time or are deemed irrelevant based on domain knowledge (which we currently don't have), we would drop them here.\n",
        "# For now, assuming all 591 features are potential predictors, we'll keep them."
      ],
      "metadata": {
        "id": "MIWctBLMxzyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nShape of the final cleaned and imputed data:\")\n",
        "print(df_imputed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVp3qSLsx73Z",
        "outputId": "2d735e9f-23c6-4d8e-9aa9-bc2b48192112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of the final cleaned and imputed data:\n",
            "(88688, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step:\n",
        " * We first checked for missing values and their percentages.\n",
        " * We decided to drop columns with more than 50% missing values to avoid heavily relying on imputed data for those features. The threshold can be adjusted based on further analysis or domain knowledge.\n",
        " * For the remaining missing values, we used mean imputation. This is a simple approach; more advanced techniques like median imputation or model-based imputation could be considered.\n",
        " * We've kept all the remaining features for now, as we lack specific domain knowledge to identify and drop irrelevant ones."
      ],
      "metadata": {
        "id": "5Br935QHyBVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data Analysis & Visualization\n",
        "\n",
        "\n",
        "Let's perform some statistical analysis and create visualizations to understand the data better."
      ],
      "metadata": {
        "id": "LN-MAzJAyYhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comments on Analysis:\n",
        " * Target Variable Distribution: The bar plot confirms the imbalance in the target variable, with significantly more 'Pass' outcomes than 'Fail' outcomes. This imbalance needs to be addressed during preprocessing to avoid biased model performance.\n",
        "\n",
        " * Univariate Analysis (Feature Distributions): The histograms of the sample features show varying distributions. Some appear roughly normal, while others might be skewed. This information can be useful for choosing appropriate preprocessing techniques and models.\n",
        "\n",
        " * Bivariate Analysis (Feature vs. Target): The box plots show the distribution of the sample features for both 'Pass' and 'Fail' outcomes. Differences in the medians and spreads might indicate that certain features are more influential in determining the yield.\n",
        "\n",
        " * Multivariate Analysis (Correlation): The correlation heatmap helps us understand the linear relationships between features. Highly correlated features might introduce redundancy in the model, and we might consider dimensionality reduction techniques or feature selection to address this. We've only visualized the correlation of the top few features due to the high dimensionality of the dataset."
      ],
      "metadata": {
        "id": "5tjUHosGyzx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your original dataframe\n",
        "df = pd.read_csv('sensor-data.csv')  # Replace with your actual file path\n",
        "\n",
        "# Print column names to check for any issues\n",
        "print(\"Column names in the DataFrame:\", df.columns)\n",
        "\n",
        "# If you're working with a specific column, make sure the column name is correct\n",
        "# For example, if you want to handle missing values for numeric columns:\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Check if the columns exist and then proceed\n",
        "print(\"Numeric columns:\", numeric_cols)\n",
        "\n",
        "# Proceed with filling missing values in numeric columns\n",
        "df_imputed = df.copy()\n",
        "df_imputed[numeric_cols] = df_imputed[numeric_cols].fillna(df_imputed[numeric_cols].mean())\n",
        "\n",
        "# For non-numeric columns, handle them as needed (e.g., using a default value)\n",
        "# Check if a column exists before filling its missing values\n",
        "if 'date_column' in df_imputed.columns:\n",
        "    df_imputed['date_column'] = df_imputed['date_column'].fillna(pd.to_datetime('2022-01-01'))\n",
        "\n",
        "if 'text_column' in df_imputed.columns:\n",
        "    df_imputed['text_column'] = df_imputed['text_column'].fillna('Unknown')\n",
        "\n",
        "# Check for missing values after imputation\n",
        "print(\"\\nNumber of missing values after imputation:\")\n",
        "print(df_imputed.isnull().sum().max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smuSq9q-qp5t",
        "outputId": "1e7aa17b-24ff-440a-b3b6-5bdfd854b3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in the DataFrame: Index(['time', 'power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "Numeric columns: Index(['power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "\n",
            "Number of missing values after imputation:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Data Pre-processing\n",
        "\n",
        "Now, let's prepare the data for model training."
      ],
      "metadata": {
        "id": "Ok1FfoL_zh6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this preprocessing stage:\n",
        " * We separated the features (X) from the target variable (y).\n",
        " * We addressed the target imbalance using SMOTE (Synthetic Minority Over-sampling Technique). SMOTE creates synthetic samples of the minority class to balance the class distribution.\n",
        " * We performed a train-test split with an 80/20 ratio, using stratify=y_resampled to ensure that the class proportions are maintained in both the training and testing sets after balancing.\n",
        " * We standardized the features using StandardScaler. This scales the features to have zero mean and unit variance, which can be beneficial for many machine learning algorithms.\n",
        " * We compared the descriptive statistics of the original, training, and testing sets (after scaling) to ensure that the splitting and scaling process hasn't drastically altered the data's fundamental characteristics. The scaled data will have means close to zero and standard deviations close to one."
      ],
      "metadata": {
        "id": "iXvvkESQq4PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your original dataframe\n",
        "df = pd.read_csv('sensor-data.csv')  # Replace with your actual file path\n",
        "\n",
        "# Print column names to check for any issues\n",
        "print(\"Column names in the DataFrame:\", df.columns)\n",
        "\n",
        "# If you're working with a specific column, make sure the column name is correct\n",
        "# For example, if you want to handle missing values for numeric columns:\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Check if the columns exist and then proceed\n",
        "print(\"Numeric columns:\", numeric_cols)\n",
        "\n",
        "# Proceed with filling missing values in numeric columns\n",
        "df_imputed = df.copy()\n",
        "df_imputed[numeric_cols] = df_imputed[numeric_cols].fillna(df_imputed[numeric_cols].mean())\n",
        "\n",
        "# For non-numeric columns, handle them as needed (e.g., using a default value)\n",
        "# Check if a column exists before filling its missing values\n",
        "if 'date_column' in df_imputed.columns:\n",
        "    df_imputed['date_column'] = df_imputed['date_column'].fillna(pd.to_datetime('2022-01-01'))\n",
        "\n",
        "if 'text_column' in df_imputed.columns:\n",
        "    df_imputed['text_column'] = df_imputed['text_column'].fillna('Unknown')\n",
        "\n",
        "# Check for missing values after imputation\n",
        "print(\"\\nNumber of missing values after imputation:\")\n",
        "print(df_imputed.isnull().sum().max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtNEJfz1rCRL",
        "outputId": "f39df465-ab7c-47dc-ebd4-d59a231f46a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in the DataFrame: Index(['time', 'power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "Numeric columns: Index(['power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "\n",
            "Number of missing values after imputation:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your original dataframe\n",
        "df = pd.read_csv('sensor-data.csv')  # Replace with your actual file path\n",
        "\n",
        "# Print column names to check for any issues\n",
        "print(\"Column names in the DataFrame:\", df.columns)\n",
        "\n",
        "# If you're working with a specific column, make sure the column name is correct\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Check if the columns exist and then proceed\n",
        "print(\"Numeric columns:\", numeric_cols)\n",
        "\n",
        "# Proceed with filling missing values in numeric columns\n",
        "df_imputed = df.copy()\n",
        "df_imputed[numeric_cols] = df_imputed[numeric_cols].fillna(df_imputed[numeric_cols].mean())\n",
        "\n",
        "# Handle non-numeric columns (if needed)\n",
        "if 'date_column' in df_imputed.columns:\n",
        "    df_imputed['date_column'] = df_imputed['date_column'].fillna(pd.to_datetime('2022-01-01'))\n",
        "\n",
        "if 'text_column' in df_imputed.columns:\n",
        "    df_imputed['text_column'] = df_imputed['text_column'].fillna('Unknown')\n",
        "\n",
        "# Example of adding a comment correctly:\n",
        "# Model 2: Random Forest\n",
        "\n",
        "# Check for missing values after imputation\n",
        "print(\"\\nNumber of missing values after imputation:\")\n",
        "print(df_imputed.isnull().sum().max())\n",
        "\n",
        "# If you're referring to \"Model 2\" in a comment, use the '#' symbol before the text:\n",
        "# Model 2: Random Forest\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MxYvB-MrZB4",
        "outputId": "0d7b1c88-69dd-43b5-c35c-a2afd14027c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in the DataFrame: Index(['time', 'power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "Numeric columns: Index(['power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "\n",
            "Number of missing values after imputation:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First things first, let's import the necessary libraries and load the dataset.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your original dataframe\n",
        "df = pd.read_csv('sensor-data.csv')  # Replace with your actual file path\n",
        "\n",
        "# Print column names to check for any issues\n",
        "print(\"Column names in the DataFrame:\", df.columns)\n",
        "\n",
        "# If you're working with a specific column, make sure the column name is correct\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Check if the columns exist and then proceed\n",
        "print(\"Numeric columns:\", numeric_cols)\n",
        "\n",
        "# Proceed with filling missing values in numeric columns\n",
        "df_imputed = df.copy()\n",
        "df_imputed[numeric_cols] = df_imputed[numeric_cols].fillna(df_imputed[numeric_cols].mean())\n",
        "\n",
        "# Handle non-numeric columns (if needed)\n",
        "if 'date_column' in df_imputed.columns:\n",
        "    df_imputed['date_column'] = df_imputed['date_column'].fillna(pd.to_datetime('2022-01-01'))\n",
        "\n",
        "if 'text_column' in df_imputed.columns:\n",
        "    df_imputed['text_column'] = df_imputed['text_column'].fillna('Unknown')\n",
        "\n",
        "# Check for missing values after imputation\n",
        "print(\"\\nNumber of missing values after imputation:\")\n",
        "print(df_imputed.isnull().sum().max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFzIhOdPrnA7",
        "outputId": "427020cc-967d-4db8-81ce-cb3ab5c83f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in the DataFrame: Index(['time', 'power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "Numeric columns: Index(['power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "\n",
            "Number of missing values after imputation:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Model Training, Testing, and Tuning\n",
        "\n",
        "Now, let's train and evaluate a few different classification models.\n",
        "\n",
        "Model 1: Logistic Regression"
      ],
      "metadata": {
        "id": "TfOFsvRk0Zan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Step 1: Check current directory and list files\n",
        "import os\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "print(\"Files in current directory:\", os.listdir())\n",
        "\n",
        "# Step 2: Try reading the file\n",
        "try:\n",
        "    df = pd.read_csv('sensor-data.csv')\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ File not found. Please upload 'sensor-data.csv' or correct the file path.\")\n",
        "    raise\n",
        "\n",
        "# Step 3: Show column names to check for target column\n",
        "print(\"\\nColumns in dataset:\", df.columns)\n",
        "\n",
        "# Step 4: Set the target column — update this if needed\n",
        "target_column = 'target'  # change if your actual column is different\n",
        "\n",
        "# Step 5: Check if target exists\n",
        "if target_column not in df.columns:\n",
        "    print(f\"❌ Target column '{target_column}' not found. Please change it.\")\n",
        "else:\n",
        "    # Step 6: Proceed only with numeric features\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Keep only numeric columns\n",
        "    X = X.select_dtypes(include=['number'])\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    # Model training and cross-validation\n",
        "    model = LogisticRegression()\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "    print(\"\\n✅ Cross-validation scores:\", scores)\n",
        "    print(\"✅ Mean accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmQLFVy6v8k1",
        "outputId": "8c2c13b1-75a1-4315-9ec7-fb834ac3aea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n",
            "Files in current directory: ['.config', 'sensor-data.csv', 'sensor-data (2).csv', 'sensor-data (1).csv', 'sensor-data (3).csv', 'sample_data']\n",
            "Dataset loaded successfully!\n",
            "\n",
            "Columns in dataset: Index(['time', 'power', 'temp', 'humidity', 'light', 'CO2', 'dust'], dtype='object')\n",
            "❌ Target column 'target' not found. Please change it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2: Random Forest"
      ],
      "metadata": {
        "id": "OOa4MkQvxJp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import libraries\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Step 2: Upload the CSV file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 3: Load the uploaded CSV into a DataFrame\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['sensor-data.csv']))\n",
        "\n",
        "# Step 4: Now you can use your DataFrame\n",
        "print(df.head())  # This will show the first few rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "BAhtlMRNRtlf",
        "outputId": "be8511bf-2390-4428-d47b-d43bbbad9353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f09601bb-f05d-4006-8645-6af52fc6a602\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f09601bb-f05d-4006-8645-6af52fc6a602\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sensor-data.csv to sensor-data.csv\n",
            "                  time  power  temp  humidity  light  CO2   dust\n",
            "0  2015-08-01 00:00:28    0.0    32        40      0  973  27.80\n",
            "1  2015-08-01 00:00:58    0.0    32        40      0  973  27.09\n",
            "2  2015-08-01 00:01:28    0.0    32        40      0  973  34.50\n",
            "3  2015-08-01 00:01:58    0.0    32        40      0  973  28.43\n",
            "4  2015-08-01 00:02:28    0.0    32        40      0  973  27.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "S9si1ptHSkgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5qwZ1c0Qt81c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Step 2: Upload the dataset\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 3: Automatically read the uploaded file\n",
        "filename = next(iter(uploaded))  # get the uploaded filename\n",
        "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "# Step 4: Prepare the data\n",
        "# IMPORTANT: Replace 'target_column_name' with your actual target column name\n",
        "# Check if the target column exists in the DataFrame\n",
        "target_column_name = 'target'  # Replace with your actual target column name if different\n",
        "if target_column_name in df.columns:\n",
        "    X = df.drop(target_column_name, axis=1)   # Features (input columns)\n",
        "    y = df[target_column_name]                # Target (output column)\n",
        "else:\n",
        "    print(f\"Error: Target column '{target_column_name}' not found in the DataFrame. Please check your data.\")\n",
        "    # You can raise an exception here if needed:\n",
        "    # raise KeyError(f\"Target column '{target_column_name}' not found in the DataFrame.\")\n",
        "    # or handle the case accordingly\n",
        "\n",
        "# ... (rest of the code remains the same)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "oV-SSOaxWN3B",
        "outputId": "43daa3d7-3043-42cd-f756-e7feac4cbdc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-158a9bba-2a93-456c-9f32-b28d457df25a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-158a9bba-2a93-456c-9f32-b28d457df25a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sensor-data.csv to sensor-data (5).csv\n",
            "Error: Target column 'target' not found in the DataFrame. Please check your data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 4: Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "cLPVoXD2tXfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Step 2: Upload the dataset\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))  # Get the uploaded file name automatically\n",
        "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "# Step 3: Prepare the data\n",
        "# IMPORTANT: Replace '-1' with your actual target column name if it's different\n",
        "# Check if the target column exists in the DataFrame\n",
        "target_column_name = '-1'  # Assuming '-1' is the actual target column name\n",
        "if target_column_name in df.columns:\n",
        "    X = df.drop(target_column_name, axis=1)  # Features (input columns)\n",
        "    y = df[target_column_name]               # Target (output column)\n",
        "else:\n",
        "    print(f\"Error: Target column '{target_column_name}' not found in the DataFrame. Please check your data.\")\n",
        "    # You can raise an exception here if needed:\n",
        "    # raise KeyError(f\"Target column '{target_column_name}' not found in the DataFrame.\")\n",
        "    # or handle the case accordingly\n",
        "\n",
        "# Step 4:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ecgQIxr-XXfY",
        "outputId": "999d375c-881d-416e-ca40-db6caf0febef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b8c3912f-b579-4cf9-82f8-e3496c6ed07d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b8c3912f-b579-4cf9-82f8-e3496c6ed07d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sensor-data.csv to sensor-data (7).csv\n",
            "Error: Target column '-1' not found in the DataFrame. Please check your data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This initial exploration gives us a glimpse into the data:\n",
        "\n",
        " * We have 1567 rows (production entities) and 592 columns (591 features + 1 target variable).\n",
        " * The features seem to be numerical.\n",
        " * The target variable '-1' represents the yield (1 for Fail, -1 for Pass).\n",
        " * The describe() output provides basic statistics like mean, standard deviation, and percentiles for each feature. This can give us an initial idea of the data's spread and potential outliers.\n",
        " * The target variable distribution shows an imbalance, with more 'Pass' (-1) instances than 'Fail' (1). This will need to be addressed during preprocessing."
      ],
      "metadata": {
        "id": "iI0Qj6xQ1HLd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpPsQZFNX2Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLR8DJeIX2b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "nymWaMNmzOTX"
      }
    }
  ]
}